#!/usr/bin/env python3
"""
Performance —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ v1.2.0 ‚Äî Parallel processing
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ concurrency –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
"""
import asyncio
import time
from pathlib import Path

from tg_parser.config import settings
from tg_parser.processing import create_processing_pipeline
from tg_parser.storage.sqlite import Database, DatabaseConfig
from tg_parser.storage.sqlite.processed_document_repo import SQLiteProcessedDocumentRepo
from tg_parser.storage.sqlite.processing_failure_repo import SQLiteProcessingFailureRepo
from tg_parser.storage.sqlite.raw_message_repo import SQLiteRawMessageRepo


async def test_concurrency(
    concurrency: int,
    provider: str = "ollama",
    model: str = "qwen3:8b",
    message_count: int = 20,
    channel_id: str = "labdiagnostica_logical"
):
    """–¢–µ—Å—Ç —Å –∑–∞–¥–∞–Ω–Ω—ã–º concurrency"""
    print(f"\n{'='*70}")
    print(f"‚ö° Testing concurrency={concurrency}")
    print(f"{'='*70}\n")
    
    # Database setup
    config = DatabaseConfig(
        ingestion_state_path=settings.ingestion_state_db_path,
        raw_storage_path=settings.raw_storage_db_path,
        processing_storage_path=settings.processing_storage_db_path,
    )
    db = Database(config)
    await db.init()
    
    try:
        raw_session = db.raw_storage_session()
        processing_session = db.processing_storage_session()
        
        try:
            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
            raw_repo = SQLiteRawMessageRepo(raw_session)
            processed_repo = SQLiteProcessedDocumentRepo(processing_session)
            failure_repo = SQLiteProcessingFailureRepo(processing_session)
            
            # Pipeline
            pipeline = create_processing_pipeline(
                provider=provider,
                model=model,
                processed_doc_repo=processed_repo,
                failure_repo=failure_repo,
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º raw —Å–æ–æ–±—â–µ–Ω–∏—è
            all_raw = await raw_repo.list_by_channel(channel_id)
            if not all_raw:
                print(f"‚ùå No raw messages found")
                return None
            
            # –ë–µ—Ä—ë–º –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            raw_messages = all_raw[:message_count]
            print(f"üì¶ Processing {len(raw_messages)} messages")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞
            start = time.time()
            processed_docs = await pipeline.process_batch(
                raw_messages,
                force=True,  # –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
                concurrency=concurrency
            )
            elapsed = time.time() - start
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            success_count = len(processed_docs)
            failed_count = len(raw_messages) - success_count
            avg_time = elapsed / len(raw_messages) if raw_messages else 0
            throughput = len(raw_messages) / elapsed if elapsed > 0 else 0
            
            print(f"\nüìä Results:")
            print(f"  ‚úÖ Success: {success_count}/{len(raw_messages)}")
            print(f"  ‚è±Ô∏è  Total time: {elapsed:.2f}s")
            print(f"  ‚ö° Throughput: {throughput:.2f} msg/sec")
            print(f"  üìà Avg time: {avg_time:.2f}s per message")
            
            return {
                "concurrency": concurrency,
                "message_count": len(raw_messages),
                "success_count": success_count,
                "failed_count": failed_count,
                "total_time": elapsed,
                "avg_time": avg_time,
                "throughput": throughput,
            }
            
        finally:
            await raw_session.close()
            await processing_session.close()
            if hasattr(pipeline, "llm_client") and hasattr(pipeline.llm_client, "close"):
                await pipeline.llm_client.close()
    finally:
        await db.close()


async def main():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å performance —Ç–µ—Å—Ç—ã"""
    print("üöÄ TG_parser v1.2.0 ‚Äî Performance Testing")
    print("=" * 70)
    
    # –¢–µ—Å—Ç—ã —Å —Ä–∞–∑–Ω—ã–º concurrency
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
    message_count = 15  # 15 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞
    concurrency_levels = [1, 3, 5]
    
    results = []
    baseline_time = None
    
    for concurrency in concurrency_levels:
        try:
            result = await test_concurrency(
                concurrency=concurrency,
                message_count=message_count
            )
            if result:
                results.append(result)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º baseline (concurrency=1)
                if concurrency == 1:
                    baseline_time = result["total_time"]
        except Exception as e:
            print(f"\n‚ùå Test failed for concurrency={concurrency}: {e}")
            import traceback
            traceback.print_exc()
    
    # Summary —Å —Ä–∞—Å—á—ë—Ç–æ–º speedup
    print(f"\n{'='*70}")
    print("üìä PERFORMANCE SUMMARY")
    print(f"{'='*70}\n")
    print(f"{'Concurrency':<12} {'Time':<10} {'Throughput':<15} {'Speedup':<10}")
    print("-" * 70)
    
    for r in results:
        speedup = baseline_time / r["total_time"] if baseline_time and baseline_time > 0 else 1.0
        print(
            f"{r['concurrency']:<12} "
            f"{r['total_time']:.2f}s{' ':<5} "
            f"{r['throughput']:.2f} msg/s{' ':<5} "
            f"{speedup:.2f}x"
        )
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:")
    if len(results) >= 2:
        best = max(results, key=lambda x: x["throughput"])
        print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π concurrency: {best['concurrency']}")
        print(f"   Throughput: {best['throughput']:.2f} msg/sec")


if __name__ == "__main__":
    asyncio.run(main())

