# Multi-LLM Configuration Guide

**Version**: v3.0.0-alpha.3  
**Date**: 28 –¥–µ–∫–∞–±—Ä—è 2025

> **Note**: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –≤ Pipeline v1.2, —Ç–∞–∫ –∏ –≤ Multi-Agent Architecture v3.0 —Å Agent Observability.

---

## üìã –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –°–æ–∑–¥–∞–π—Ç–µ .env —Ñ–∞–π–ª

```bash
cp .env.example .env
```

### 2. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ API –∫–ª—é—á–∏ –≤ .env

```env
# –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
LLM_PROVIDER=openai

# –î–æ–±–∞–≤—å—Ç–µ API key –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
OPENAI_API_KEY=sk-...
```

### 3. –ì–æ—Ç–æ–≤–æ!

```bash
# –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env
python -m tg_parser.cli process --channel my_channel
```

---

## üîë –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á–∏

### OpenAI (GPT-4, GPT-4o-mini)

1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ https://platform.openai.com/
2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª "API keys": https://platform.openai.com/api-keys
3. –ù–∞–∂–º–∏—Ç–µ "Create new secret key"
4. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á –≤ `.env`:

```env
OPENAI_API_KEY=sk-proj-...
```

**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$0.15-0.60 –∑–∞ 1000 —Å–æ–æ–±—â–µ–Ω–∏–π (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏)

---

### Anthropic Claude (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ https://console.anthropic.com/
2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ "API Keys"
3. –ù–∞–∂–º–∏—Ç–µ "Create Key"
4. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á –≤ `.env`:

```env
ANTHROPIC_API_KEY=sk-ant-...
LLM_PROVIDER=anthropic
```

**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$0.30 –∑–∞ 1000 —Å–æ–æ–±—â–µ–Ω–∏–π  
**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, –Ω–∞–¥—ë–∂–Ω—ã–π API

---

### Google Gemini (—Å–∞–º—ã–π –¥–µ—à–µ–≤—ã–π)

1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://aistudio.google.com/app/apikey
2. –í–æ–π–¥–∏—Ç–µ —á–µ—Ä–µ–∑ Google –∞–∫–∫–∞—É–Ω—Ç
3. –ù–∞–∂–º–∏—Ç–µ "Create API Key"
4. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á –≤ `.env`:

```env
GEMINI_API_KEY=AIza...
LLM_PROVIDER=gemini
```

**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$0.075 –∑–∞ 1000 —Å–æ–æ–±—â–µ–Ω–∏–π (–≤ 2-4 —Ä–∞–∑–∞ –¥–µ—à–µ–≤–ª–µ OpenAI/Anthropic)  
**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: API –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º (–Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å)

---

### Ollama (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –ª–æ–∫–∞–ª—å–Ω–æ)

Ollama ‚Äî —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π LLM —Å–µ—Ä–≤–µ—Ä. **API key –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è!**

#### macOS

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
brew install ollama

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
ollama serve

# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
ollama pull llama3.2

# –ì–æ—Ç–æ–≤–æ! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ .env:
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2
```

#### Linux

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
curl -fsSL https://ollama.com/install.sh | sh

# –ó–∞–ø—É—Å–∫
ollama serve

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
ollama pull llama3.2
```

#### Docker

```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ docker-compose (Ollama —É–∂–µ –≤–∫–ª—é—á–µ–Ω)
docker-compose up -d ollama
docker-compose exec ollama ollama pull llama3.2
```

**–°—Ç–æ–∏–º–æ—Å—Ç—å**: –ë–µ—Å–ø–ª–∞—Ç–Ω–æ!  
**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: 
- –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å (–¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–∫–∏–¥–∞—é—Ç –≤–∞—à—É –º–∞—à–∏–Ω—É)
- –ù–µ—Ç rate limits
- –ù–µ—Ç –∑–∞—Ç—Ä–∞—Ç –Ω–∞ API

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**: 
- –ú–∏–Ω–∏–º—É–º 8GB RAM (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16GB)
- ~4GB –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ –¥–ª—è –º–æ–¥–µ–ª–∏

---

## üöÄ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### OpenAI (default)

```bash
export OPENAI_API_KEY=sk-...
python -m tg_parser.cli process --channel my_channel
```

### Anthropic Claude

```bash
export ANTHROPIC_API_KEY=sk-ant-...
python -m tg_parser.cli process --channel my_channel --provider anthropic
```

### Google Gemini

```bash
export GEMINI_API_KEY=AIza...
python -m tg_parser.cli process --channel my_channel --provider gemini
```

### Ollama (–ª–æ–∫–∞–ª—å–Ω–æ)

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å Ollama server
ollama serve

# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
python -m tg_parser.cli process --channel my_channel --provider ollama --model llama3.2
```

---

## ‚öôÔ∏è –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ CLI

API –∫–ª—é—á–∏ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å **–Ω–µ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ .env**, –Ω–æ –∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

```bash
# –í—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã
OPENAI_API_KEY=sk-test python -m tg_parser.cli process --channel test

# –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ export
export ANTHROPIC_API_KEY=sk-ant-...
python -m tg_parser.cli process --channel my_channel --provider anthropic
```

---

## üê≥ Docker

### –° .env —Ñ–∞–π–ª–æ–º

```bash
# .env –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç—Å—è docker-compose
docker-compose run tg_parser process --channel my_channel
```

### –° –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
docker run --rm \
  -e OPENAI_API_KEY=sk-... \
  -e LLM_PROVIDER=openai \
  tg_parser process --channel my_channel
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ

- ‚úÖ –•—Ä–∞–Ω–∏—Ç—å –∫–ª—é—á–∏ –≤ `.env` (—Ñ–∞–π–ª –≤ `.gitignore`)
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ–∫—Ä–µ—Ç—ã –≤ CI/CD (GitHub Secrets)
- ‚úÖ –†–µ–≥—É–ª—è—Ä–Ω–æ —Ä–æ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–∏

### ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ

- ‚ùå –•–∞—Ä–¥–∫–æ–¥–∏—Ç—å –∫–ª—é—á–∏ –≤ –∫–æ–¥–µ
- ‚ùå –ö–æ–º–º–∏—Ç–∏—Ç—å `.env` –≤ git
- ‚ùå –î–µ–ª–∏—Ç—å—Å—è –∫–ª—é—á–∞–º–∏ –ø—É–±–ª–∏—á–Ω–æ
- ‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∫–ª—é—á –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

| –ü—Ä–æ–≤–∞–π–¥–µ—Ä | –°—Ç–æ–∏–º–æ—Å—Ç—å* | –ö–∞—á–µ—Å—Ç–≤–æ | –°–∫–æ—Ä–æ—Å—Ç—å | –ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å |
|-----------|------------|----------|----------|------------|
| **OpenAI** | $0.15-0.60 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Anthropic** | $0.30 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Gemini** | $0.075 | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Ollama** | –ë–µ—Å–ø–ª–∞—Ç–Ω–æ | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

*–ó–∞ 1000 —Å–æ–æ–±—â–µ–Ω–∏–π

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

- **Production**: Anthropic Claude (–ª—É—á—à–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–æ/–Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å)
- **Development**: Ollama (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –ø—Ä–∏–≤–∞—Ç–Ω–æ)
- **Cost-effective**: Gemini (–¥–µ—à–µ–≤–æ, –Ω–æ –º–µ–Ω–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ)
- **–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç**: OpenAI (—Å—Ç–∞–Ω–¥–∞—Ä—Ç –∏–Ω–¥—É—Å—Ç—Ä–∏–∏)

---

## üÜò Troubleshooting

### "API key not provided"

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ .env –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
python -c "from tg_parser.config import settings; print(settings.openai_api_key)"

# –ï—Å–ª–∏ None, —Å–æ–∑–¥–∞–π—Ç–µ .env –∏–∑ .env.example
cp .env.example .env
# –ó–∞–ø–æ–ª–Ω–∏—Ç–µ API –∫–ª—é—á–∏
```

### "Unknown LLM provider"

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
python -m tg_parser.cli process --help

# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: openai, anthropic, gemini, ollama
```

### "Ollama connection refused"

```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω
ollama serve

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
curl http://localhost:11434/api/version
```

---

## üìö –°–º. —Ç–∞–∫–∂–µ

- [README.md](../README.md) ‚Äî –û—Å–Ω–æ–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [DEVELOPMENT_ROADMAP.md](../DEVELOPMENT_ROADMAP.md) ‚Äî Roadmap v1.2
- [SESSION_HANDOFF_v1.2.md](docs/notes/SESSION_HANDOFF_v1.2.md) ‚Äî –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

---

**Version**: 1.1  
**Last Updated**: 28 –¥–µ–∫–∞–±—Ä—è 2025

