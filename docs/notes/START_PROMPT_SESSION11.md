# Session 11: v1.1 Developer Agent ‚Äî "Stability & Configurability"

## –†–æ–ª—å

–ü—Ä–∏–≤–µ—Ç! –¢—ã Developer Agent –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Ä—Å–∏–∏ **v1.1.0** –ø—Ä–æ–µ–∫—Ç–∞ TG_parser. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **Configurable Prompts (YAML)** –∏ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥.

---

## üìã –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞

**TG_parser** ‚Äî production-ready —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–±–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ Telegram-–∫–∞–Ω–∞–ª–æ–≤, –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ LLM –∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

### –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (v1.0)
- ‚úÖ **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: 99.76% —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –Ω–∞ 846 —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
- ‚úÖ **–¢–µ—Å—Ç—ã**: 85 —Ç–µ—Å—Ç–æ–≤, 100% –ø—Ä–æ—Ö–æ–¥—è—Ç
- ‚úÖ **Production-ready**: –ø–æ–ª–Ω—ã–π E2E pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚ö†Ô∏è **–ü—Ä–æ–º–ø—Ç—ã**: —Ö–∞—Ä–¥–∫–æ–∂–µ–Ω—ã –≤ Python —Ñ–∞–π–ª–∞—Ö
- ‚ö†Ô∏è **TODOs**: 2 –Ω–µ—Ä–µ—à—ë–Ω–Ω—ã—Ö –≤ –∫–æ–¥–µ

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```
tg_parser/
‚îú‚îÄ‚îÄ cli/           # Typer CLI (7 –∫–æ–º–∞–Ω–¥)
‚îú‚îÄ‚îÄ config/        # Pydantic-settings
‚îú‚îÄ‚îÄ domain/        # –î–æ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (Pydantic v2)
‚îú‚îÄ‚îÄ ingestion/     # Telethon client
‚îú‚îÄ‚îÄ processing/    # LLM processing ‚Üê –û–°–ù–û–í–ù–û–ô –§–û–ö–£–°
‚îÇ   ‚îú‚îÄ‚îÄ llm/       # OpenAI client
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py           ‚Üê –í—ã–Ω–µ—Å—Ç–∏ –≤ YAML
‚îÇ   ‚îú‚îÄ‚îÄ topicization_prompts.py  ‚Üê –í—ã–Ω–µ—Å—Ç–∏ –≤ YAML
‚îÇ   ‚îî‚îÄ‚îÄ topicization.py
‚îú‚îÄ‚îÄ storage/       # SQLite —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
‚îî‚îÄ‚îÄ export/        # –≠–∫—Å–ø–æ—Ä—Ç KB entries + topics
```

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

### üî¥ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã

| –î–æ–∫—É–º–µ–Ω—Ç | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|----------|----------|-----------|
| `DEVELOPMENT_ROADMAP.md` | **–ü–ª–∞–Ω v1.1** ‚Äî –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ | ‚≠ê‚≠ê‚≠ê |
| `docs/LLM_PROMPTS.md` | –¢–µ–∫—É—â–∏–µ –ø—Ä–æ–º–ø—Ç—ã ‚Äî —á—Ç–æ –Ω—É–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ YAML | ‚≠ê‚≠ê‚≠ê |
| `tg_parser/processing/prompts.py` | –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–º–ø—Ç–æ–≤ processing | ‚≠ê‚≠ê‚≠ê |
| `tg_parser/processing/topicization_prompts.py` | –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–º–ø—Ç–æ–≤ topicization | ‚≠ê‚≠ê‚≠ê |

### üü° –î–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã

| –î–æ–∫—É–º–µ–Ω—Ç | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|
| `README.md` | –û–±—â–∏–π –æ–±–∑–æ—Ä, CLI –∫–æ–º–∞–Ω–¥—ã |
| `DOCUMENTATION_INDEX.md` | –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (32 –¥–æ–∫—É–º–µ–Ω—Ç–∞) |
| `docs/architecture.md` | –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, DDL —Å—Ö–µ–º—ã |
| `docs/pipeline.md` | –î–µ—Ç–∞–ª–∏ pipeline |
| `docs/technical-requirements.md` | –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è TR-* |
| `docs/DATA_FLOW.md` | –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É |

### üü¢ –î–ª—è —Å–ø—Ä–∞–≤–∫–∏ –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

| –î–æ–∫—É–º–µ–Ω—Ç | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|
| `tg_parser/processing/pipeline.py` | Processing pipeline ‚Äî –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–æ–º–ø—Ç—ã |
| `tg_parser/processing/topicization.py` | Topicization ‚Äî –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–æ–º–ø—Ç—ã |
| `tg_parser/cli/export_cmd.py` | –°–æ–¥–µ—Ä–∂–∏—Ç TODOs –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è |
| `tg_parser/config/settings.py` | –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Äî –¥–æ–±–∞–≤–∏—Ç—å `prompts_dir` |
| `tests/test_processing_pipeline.py` | –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Å—Ç—ã processing |

---

## üì§ –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏–º –∞–≥–µ–Ω—Ç–∞–º

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

| –î–æ–∫—É–º–µ–Ω—Ç | –ß—Ç–æ –æ–±–Ω–æ–≤–∏—Ç—å |
|----------|--------------|
| `docs/notes/SESSION_HANDOFF_v1.1.md` | ‚≠ê **–°–û–ó–î–ê–¢–¨** ‚Äî handoff –¥–ª—è v1.2 –∞–≥–µ–Ω—Ç–∞ |
| `DEVELOPMENT_ROADMAP.md` | –û—Ç–º–µ—Ç–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ v1.1 |
| `docs/notes/current-state.md` | –û–±–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ |
| `CHANGELOG.md` | ‚≠ê **–°–û–ó–î–ê–¢–¨** ‚Äî –∏—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π |

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ SESSION_HANDOFF_v1.1.md

```markdown
# Session 11 Handoff ‚Äî v1.1.0 Complete

## ‚úÖ –ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
- [ ] Configurable Prompts (YAML)
- [ ] list_all() –≤ ProcessedDocumentRepo
- [ ] Usernames –∏–∑ IngestionStateRepo
- [ ] Auto-retry –¥–ª—è failed messages
- [ ] –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è LLM

## üìÅ –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã
- prompts/processing.yaml
- prompts/topicization.yaml
- prompts/supporting_items.yaml
- tg_parser/processing/prompt_loader.py

## ‚ö†Ô∏è –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
...

## üöÄ –ì–æ—Ç–æ–≤–æ –¥–ª—è v1.2
- [ ] Multi-LLM support –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
- [ ] –ü—Ä–æ–º–ø—Ç—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
```

---

## üéØ –ó–∞–¥–∞—á–∏ v1.1.0 (–ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã)

### –ù–µ–¥–µ–ª—è 1 ‚Äî High Priority

#### –ó–∞–¥–∞—á–∞ 1: ‚≠ê Configurable Prompts (YAML)
**–í—Ä–µ–º—è**: 6-8 —á–∞—Å–æ–≤  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: HIGHEST

**–°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É:**
```
prompts/
‚îú‚îÄ‚îÄ processing.yaml       # Processing –ø—Ä–æ–º–ø—Ç—ã
‚îú‚îÄ‚îÄ topicization.yaml     # Topicization –ø—Ä–æ–º–ø—Ç—ã
‚îú‚îÄ‚îÄ supporting_items.yaml # Supporting items –ø—Ä–æ–º–ø—Ç—ã
‚îî‚îÄ‚îÄ README.md             # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
```

**–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å PromptLoader:**
```python
# tg_parser/processing/prompt_loader.py
import yaml
from pathlib import Path
from typing import Any

class PromptLoader:
    """Load prompts from YAML files with fallback to defaults."""
    
    def __init__(self, prompts_dir: Path | None = None):
        self.prompts_dir = prompts_dir or Path("prompts")
        self._cache: dict[str, dict] = {}
    
    def load(self, name: str) -> dict[str, Any]:
        """Load prompt configuration from YAML file.
        
        Args:
            name: Prompt name (e.g., "processing", "topicization")
            
        Returns:
            Dict with prompt configuration
        """
        if name in self._cache:
            return self._cache[name]
            
        path = self.prompts_dir / f"{name}.yaml"
        if path.exists():
            with open(path, encoding="utf-8") as f:
                config = yaml.safe_load(f)
        else:
            # Fallback to built-in defaults
            config = self._get_default(name)
            
        self._cache[name] = config
        return config
    
    def _get_default(self, name: str) -> dict[str, Any]:
        """Get default prompts (current hardcoded values)."""
        from . import prompts, topicization_prompts
        
        defaults = {
            "processing": {
                "system": {"prompt": prompts.PROCESSING_SYSTEM_PROMPT},
                "user": {"template": prompts.PROCESSING_USER_PROMPT_TEMPLATE},
                "model": {"temperature": 0, "max_tokens": 4096},
            },
            "topicization": {
                "system": {"prompt": topicization_prompts.TOPICIZATION_SYSTEM_PROMPT},
                "user": {"template": topicization_prompts.TOPICIZATION_USER_PROMPT_TEMPLATE},
                "model": {"temperature": 0, "max_tokens": 8192},
            },
            # ... –∏ —Ç.–¥.
        }
        return defaults.get(name, {})
    
    def get_system_prompt(self, name: str) -> str:
        """Get system prompt for specified prompt type."""
        config = self.load(name)
        return config.get("system", {}).get("prompt", "")
    
    def get_user_template(self, name: str) -> str:
        """Get user prompt template."""
        config = self.load(name)
        return config.get("user", {}).get("template", "")
    
    def get_model_settings(self, name: str) -> dict:
        """Get model settings (temperature, max_tokens, etc.)."""
        config = self.load(name)
        return config.get("model", {})
```

**–§–æ—Ä–º–∞—Ç YAML —Ñ–∞–π–ª–∞ (prompts/processing.yaml):**
```yaml
# TG_parser Processing Prompts
# Version: 1.0.0
# 
# –≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ LLM.
# –†–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –ø–æ–¥ –≤–∞—à—É –∑–∞–¥–∞—á—É.

metadata:
  version: "1.0.0"
  description: "Prompts for processing Telegram messages"
  author: "TG_parser team"

system:
  prompt: |
    You are a text processing assistant for Telegram channel messages.
    
    Your task is to analyze the message and extract structured information.
    
    For each message, provide:
    1. text_clean: Cleaned and normalized text (remove formatting artifacts, fix typos)
    2. summary: Brief summary in 1-2 sentences (or null if message is too short)
    3. topics: List of 3-7 relevant topics/themes
    4. entities: List of named entities (people, organizations, products, etc.)
    5. language: Detected language code (ru, en, etc.)
    
    IMPORTANT:
    - Respond in the SAME language as the input message
    - Output must be valid JSON
    - All fields are required (use null for optional empty values)

user:
  template: |
    Process the following Telegram message:
    
    ---
    {text}
    ---
    
    Channel: {channel_id}
    Message ID: {message_id}
    Date: {date}
    
    Respond with JSON:
    {{
      "text_clean": "...",
      "summary": "..." or null,
      "topics": ["topic1", "topic2", ...],
      "entities": ["entity1", "entity2", ...],
      "language": "ru" or "en" or ...
    }}
    
  variables:
    - text        # –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
    - channel_id  # ID –∫–∞–Ω–∞–ª–∞
    - message_id  # ID —Å–æ–æ–±—â–µ–Ω–∏—è
    - date        # –î–∞—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

model:
  temperature: 0
  max_tokens: 4096
  
# –î–ª—è GPT-5 (–±—É–¥—É—â–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ v2.0)
gpt5:
  reasoning_effort: low    # minimal | low | medium | high
  verbosity: low           # low | medium | high
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ pipeline.py:**
```python
# tg_parser/processing/pipeline.py

from .prompt_loader import PromptLoader

class ProcessingPipeline:
    def __init__(self, llm_client, prompt_loader: PromptLoader | None = None):
        self.llm = llm_client
        self.prompts = prompt_loader or PromptLoader()
    
    async def process_message(self, message: RawTelegramMessage) -> ProcessedDocument:
        system_prompt = self.prompts.get_system_prompt("processing")
        user_template = self.prompts.get_user_template("processing")
        model_settings = self.prompts.get_model_settings("processing")
        
        user_prompt = user_template.format(
            text=message.text,
            channel_id=message.channel_id,
            message_id=message.message_id,
            date=message.date.isoformat() if message.date else "",
        )
        
        response = await self.llm.complete(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            **model_settings,
        )
        # ... –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
```

**CLI —Ñ–ª–∞–≥:**
```python
# tg_parser/cli/app.py

@app.callback()
def main(
    prompts_dir: Path = typer.Option(
        None,
        "--prompts-dir",
        help="Custom prompts directory (default: ./prompts)",
    ),
):
    """TG_parser CLI."""
    if prompts_dir:
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥–∞–º–∏
        ctx.obj["prompts_dir"] = prompts_dir
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏:**
- [ ] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ `prompts/` —Å–æ–∑–¥–∞–Ω–∞ —Å 3 YAML —Ñ–∞–π–ª–∞–º–∏
- [ ] `PromptLoader` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —Å fallback –Ω–∞ defaults
- [ ] `pipeline.py` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `PromptLoader`
- [ ] `topicization.py` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `PromptLoader`
- [ ] CLI —Ñ–ª–∞–≥ `--prompts-dir` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] `prompts/README.md` –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç
- [ ] –¢–µ—Å—Ç—ã –¥–ª—è `PromptLoader` –Ω–∞–ø–∏—Å–∞–Ω—ã
- [ ] –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

---

#### –ó–∞–¥–∞—á–∞ 2: –î–æ–±–∞–≤–∏—Ç—å `list_all()` –≤ ProcessedDocumentRepo
**–í—Ä–µ–º—è**: 2 —á–∞—Å–∞

**–§–∞–π–ª**: `tg_parser/storage/sqlite/processed_document_repo.py`

```python
async def list_all(self, limit: int | None = None) -> list[ProcessedDocument]:
    """Return all processed documents across all channels.
    
    Args:
        limit: Maximum number of documents to return (None = all)
        
    Returns:
        List of ProcessedDocument objects
    """
    async with self._session() as session:
        query = select(ProcessedDocumentTable)
        if limit:
            query = query.limit(limit)
        result = await session.execute(query)
        rows = result.scalars().all()
        return [self._to_domain(row) for row in rows]
```

**–û–±–Ω–æ–≤–∏—Ç—å export_cmd.py:**
```python
# –£–±—Ä–∞—Ç—å TODO –Ω–∞ —Å—Ç—Ä–æ–∫–µ 82
if channel:
    docs = await repo.list_by_channel(channel)
else:
    docs = await repo.list_all()  # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç!
```

---

#### –ó–∞–¥–∞—á–∞ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ usernames –∏–∑ IngestionStateRepo
**–í—Ä–µ–º—è**: 3 —á–∞—Å–∞

**–§–∞–π–ª**: `tg_parser/cli/export_cmd.py` (—Å—Ç—Ä–æ–∫–∞ 99)

```python
# –ü–æ–ª—É—á–∏—Ç—å username –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –ª—É—á—à–∏—Ö Telegram URLs
async def get_channel_username(source_id: str) -> str | None:
    """Get channel username from ingestion state."""
    source = await ingestion_repo.get_source(source_id)
    return source.channel_username if source else None

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ export
channel_username = await get_channel_username(source_id)
telegram_url = resolve_telegram_url(
    channel_id=channel_id,
    message_id=message_id,
    channel_username=channel_username,  # –ü–µ—Ä–µ–¥–∞—Ç—å username!
)
```

---

#### –ó–∞–¥–∞—á–∞ 4: Auto-retry –¥–ª—è failed messages
**–í—Ä–µ–º—è**: 4 —á–∞—Å–∞

**–§–∞–π–ª**: `tg_parser/cli/process_cmd.py`

```python
@app.command()
async def process(
    channel: str = typer.Option(...),
    retry_failed: bool = typer.Option(False, "--retry-failed", help="Retry failed messages"),
    force: bool = typer.Option(False, "--force"),
):
    """Process raw messages through LLM."""
    if retry_failed:
        # –ü–æ–ª—É—á–∏—Ç—å failed messages
        failures = await failure_repo.list_by_channel(channel)
        messages_to_process = [
            await raw_repo.get_by_source_ref(f.source_ref)
            for f in failures
        ]
        typer.echo(f"Retrying {len(messages_to_process)} failed messages...")
    else:
        # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞
        ...
```

---

#### –ó–∞–¥–∞—á–∞ 5: –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ LLM
**–í—Ä–µ–º—è**: 3 —á–∞—Å–∞

**–§–∞–π–ª**: `tg_parser/processing/pipeline.py`

```python
def _validate_llm_response(self, response: dict) -> dict:
    """Validate and fix LLM response.
    
    Args:
        response: Parsed JSON from LLM
        
    Returns:
        Validated response with defaults for missing fields
        
    Raises:
        ValueError: If critical fields are missing
    """
    required_fields = ["text_clean"]
    optional_fields = {
        "summary": None,
        "topics": [],
        "entities": [],
        "language": "unknown",
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å required
    for field in required_fields:
        if field not in response or not response[field]:
            raise ValueError(f"LLM response missing required field: {field}")
    
    # –ó–∞–ø–æ–ª–Ω–∏—Ç—å defaults –¥–ª—è optional
    for field, default in optional_fields.items():
        if field not in response:
            response[field] = default
            logger.warning(f"LLM response missing optional field '{field}', using default")
    
    return response
```

---

### –ù–µ–¥–µ–ª—è 2-3 ‚Äî Medium Priority

#### –ó–∞–¥–∞—á–∞ 6: –û–±–Ω–æ–≤–∏—Ç—å current-state.md
**–í—Ä–µ–º—è**: 2 —á–∞—Å–∞

–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å `docs/notes/current-state.md` —Å —Ä–µ–∞–ª—å–Ω—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∫–æ–¥–∞.

#### –ó–∞–¥–∞—á–∞ 7: –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
**–í—Ä–µ–º—è**: 1 —á–∞—Å

```bash
mkdir -p docs/notes/archive
mv SESSION_COMPLETE.md docs/notes/archive/
mv PROCESSING_COMPLETE.md docs/notes/archive/
```

#### –ó–∞–¥–∞—á–∞ 8: –î–æ–±–∞–≤–∏—Ç—å E2E —Ç–µ—Å—Ç—ã
**–í—Ä–µ–º—è**: 4 —á–∞—Å–∞

**–§–∞–π–ª**: `tests/test_e2e_scenarios.py`

```python
import pytest
from pathlib import Path

class TestE2EScenarios:
    """End-to-end tests for typical usage scenarios."""
    
    @pytest.mark.asyncio
    async def test_custom_prompts_directory(self, tmp_path):
        """Test using custom prompts from directory."""
        # –°–æ–∑–¥–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        prompts_dir = tmp_path / "prompts"
        prompts_dir.mkdir()
        (prompts_dir / "processing.yaml").write_text("""
system:
  prompt: "Custom system prompt"
user:
  template: "Process: {text}"
model:
  temperature: 0
""")
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        loader = PromptLoader(prompts_dir)
        assert "Custom system prompt" in loader.get_system_prompt("processing")
    
    @pytest.mark.asyncio
    async def test_fallback_to_default_prompts(self):
        """Test fallback to default prompts when YAML not found."""
        loader = PromptLoader(Path("/nonexistent"))
        
        # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å default –ø—Ä–æ–º–ø—Ç
        system_prompt = loader.get_system_prompt("processing")
        assert system_prompt  # –ù–µ –ø—É—Å—Ç–æ–π
        assert "text processing" in system_prompt.lower()
```

#### –ó–∞–¥–∞—á–∞ 9: –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
**–í—Ä–µ–º—è**: 3 —á–∞—Å–∞

```python
import logging
import structlog

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ structlog
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer(),
    ],
    logger_factory=structlog.stdlib.LoggerFactory(),
)

logger = structlog.get_logger(__name__)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
logger.info("processing_message", 
    source_ref=message.source_ref,
    channel_id=message.channel_id,
)
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ
source .venv/bin/activate

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã
pytest

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ—Å—Ç
pytest tests/test_prompt_loader.py -v

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest --cov=tg_parser --cov-report=html

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–Ω—Ç–∏–Ω–≥
ruff check .
ruff format .
```

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ v1.1.0

### Must Have
- [ ] ‚≠ê –ü—Ä–æ–º–ø—Ç—ã –≤—ã–Ω–µ—Å–µ–Ω—ã –≤ YAML (3 —Ñ–∞–π–ª–∞)
- [ ] ‚≠ê `PromptLoader` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —Å fallback
- [ ] –í—Å–µ TODOs —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã (0 –≤ –∫–æ–¥–µ)
- [ ] Error rate < 0.1%
- [ ] Auto-retry —Ä–∞–±–æ—Ç–∞–µ—Ç

### Should Have
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ (`prompts/README.md`)
- [ ] E2E —Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
- [ ] –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] `current-state.md` –æ–±–Ω–æ–≤–ª—ë–Ω

### Nice to Have
- [ ] –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã
- [ ] CHANGELOG.md —Å–æ–∑–¥–∞–Ω

---

## üìä Success Metrics

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ | –¶–µ–ª—å |
|---------|---------|------|
| **Prompts in YAML** | 0 | 3 |
| Error rate | 0.24% | < 0.1% |
| TODOs –≤ –∫–æ–¥–µ | 2 | 0 |
| Test count | 85 | 95+ |

---

## üöÄ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞

```bash
# 1. –ü—Ä–æ—á–∏—Ç–∞—Ç—å roadmap
cat DEVELOPMENT_ROADMAP.md | head -300

# 2. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ–∫—É—â–∏–µ –ø—Ä–æ–º–ø—Ç—ã
cat tg_parser/processing/prompts.py
cat tg_parser/processing/topicization_prompts.py

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å TODOs
grep -r "TODO" tg_parser/

# 4. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã
pytest --tb=short -q

# 5. –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É prompts/
mkdir -p prompts
```

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

1. **–ù–µ –ª–æ–º–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Å—Ç—ã** ‚Äî –≤—Å–µ 85 –¥–æ–ª–∂–Ω—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å
2. **Backward compatibility** ‚Äî –µ—Å–ª–∏ `prompts/` –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å defaults
3. **YAML —Ñ–æ—Ä–º–∞—Ç** ‚Äî –Ω–µ JSON (–æ–±—Å—É–∂–¥–µ–Ω–æ —Å –∑–∞–∫–∞–∑—á–∏–∫–æ–º)
4. **–ù–µ –º–µ–Ω—è—Ç—å API** ‚Äî —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

---

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [DEVELOPMENT_ROADMAP.md](../../DEVELOPMENT_ROADMAP.md) ‚Äî –ø–æ–ª–Ω—ã–π roadmap
- [docs/LLM_PROMPTS.md](../LLM_PROMPTS.md) ‚Äî —Ç–µ–∫—É—â–∏–µ –ø—Ä–æ–º–ø—Ç—ã
- [REAL_CHANNEL_TEST_RESULTS.md](../../REAL_CHANNEL_TEST_RESULTS.md) ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- [docs/architecture.md](../architecture.md) ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

---

## üí¨ –ö–æ–Ω—Ç–∞–∫—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–æ–∑–¥–∞–π —Ñ–∞–π–ª `docs/notes/SESSION_HANDOFF_v1.1.md` —Å:
1. –°–ø–∏—Å–∫–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
2. –°–ø–∏—Å–∫–æ–º –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
3. –ò–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏
4. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –¥–ª—è v1.2 –∞–≥–µ–Ω—Ç–∞

---

**Version**: 1.0  
**Created**: 26 –¥–µ–∫–∞–±—Ä—è 2025  
**Target**: v1.1.0 release  
**ETA**: 2-3 –Ω–µ–¥–µ–ª–∏  
**Previous session**: Session 10 (Planning)  
**Next session**: Session 12 (v1.2 Multi-LLM)

---

**–ì–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏! –ù–∞—á–Ω–∏ —Å –ó–∞–¥–∞—á–∏ 1 ‚Äî Configurable Prompts (YAML).** üöÄ

