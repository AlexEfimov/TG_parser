# SESSION 14 ‚Äî –≠–¢–ê–ü 2B: OpenAI Agents SDK PoC

**–î–∞—Ç–∞**: 27 –¥–µ–∫–∞–±—Ä—è 2025  
**–ü—Ä–µ–¥—ã–¥—É—â–∏–π —ç—Ç–∞–ø**: 2A (HTTP API Skeleton) ‚úÖ  
**–¶–µ–ª—å**: –°–æ–∑–¥–∞—Ç—å Proof of Concept —Å OpenAI Agents SDK

---

## ‚ö†Ô∏è –í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò

### –ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã
1. **–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ**:
   ```bash
   cd /Users/alexanderefimov/TG_parser
   source .venv/bin/activate
   ```

2. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å OpenAI Agents SDK**:
   ```bash
   pip install openai-agents
   ```

3. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å API –∫–ª—é—á** (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ .env):
   ```bash
   grep OPENAI_API_KEY .env
   ```

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **Context7** –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:
  ```
  mcp_Context7_get-library-docs(
    context7CompatibleLibraryID="/openai/openai-agents-python",
    topic="..."
  )
  ```

---

## üìã –ö–æ–Ω—Ç–µ–∫—Å—Ç

### –ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–Ω–æ –≤ —Å–µ—Å—Å–∏–∏ 14:

**–≠–¢–ê–ü 1: Research** ‚úÖ
- –ò–∑—É—á–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Agents SDK
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: Agent, Tool, Runner, Handoffs
- –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ –≥–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**–≠–¢–ê–ü 2A: HTTP API Skeleton** ‚úÖ
- FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (`tg_parser/api/`)
- 8 endpoints (health, process, export)
- CLI –∫–æ–º–∞–Ω–¥–∞ `tg-parser api`
- 24 —Ç–µ—Å—Ç–∞ –¥–ª—è API
- **–í—Å–µ–≥–æ 150 —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—Ö–æ–¥—è—Ç**

### –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v1.2:

```
RawMessage ‚Üí ProcessingPipeline ‚Üí LLM (Chat Completions) ‚Üí ProcessedDocument
                    ‚Üì
              prompt + text ‚Üí response ‚Üí parse JSON
```

### –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å Agents:

```
RawMessage ‚Üí TGProcessingAgent ‚Üí [Tools] ‚Üí ProcessedDocument
                    ‚Üì
         Agent orchestrates tool calls:
         - clean_text()
         - extract_entities()
         - extract_topics()
         - generate_summary()
```

---

## üéØ –ó–∞–¥–∞—á–∏ –≠–¢–ê–ü–ê 2B

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç (15 –º–∏–Ω)

```bash
pip install openai-agents
```

```python
# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
from agents import Agent, Runner

agent = Agent(
    name="Test",
    instructions="Say hello"
)

result = Runner.run_sync(agent, "Hi")
print(result.final_output)
```

### 2. –°–æ–∑–¥–∞—Ç—å TGProcessingAgent (1-2 —á–∞—Å–∞)

**–§–∞–π–ª**: `tg_parser/agents/processing_agent.py`

```python
from agents import Agent, Runner, function_tool
from tg_parser.domain.models import RawTelegramMessage, ProcessedDocument

@function_tool
def clean_text(raw_text: str) -> str:
    """Clean and normalize text from Telegram message."""
    # Remove excessive whitespace, normalize Unicode
    import re
    text = re.sub(r'\s+', ' ', raw_text).strip()
    return text

@function_tool
def extract_topics(text: str) -> list[str]:
    """Extract main topics from text."""
    # This will be called by the agent
    # Agent will use LLM reasoning to extract topics
    return []  # Agent fills this

@function_tool
def extract_entities(text: str) -> list[dict]:
    """Extract named entities from text."""
    return []  # Agent fills this

class TGProcessingAgent:
    """Agent for processing Telegram messages."""
    
    def __init__(self, model: str = "gpt-4o-mini"):
        self.agent = Agent(
            name="TGProcessor",
            instructions=self._get_instructions(),
            tools=[clean_text, extract_topics, extract_entities],
            model=model,
        )
    
    def _get_instructions(self) -> str:
        return """
        You are an expert at processing Telegram messages for a knowledge base.
        
        For each message:
        1. Clean the text (remove noise, normalize)
        2. Extract 2-5 main topics
        3. Extract named entities (people, organizations, terms)
        4. Generate a brief summary
        
        Return structured JSON with:
        - text_clean: cleaned text
        - topics: list of topic strings
        - entities: list of {type, value, confidence}
        - summary: 1-2 sentence summary
        - language: detected language code
        """
    
    async def process(self, message: RawTelegramMessage) -> dict:
        """Process a single message through the agent."""
        result = await Runner.run(
            self.agent,
            f"Process this Telegram message:\n\n{message.text}"
        )
        return self._parse_output(result.final_output)
```

### 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å v1.2 pipeline (30 –º–∏–Ω)

–û–±—Ä–∞–±–æ—Ç–∞—Ç—å 5-10 —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑:
- v1.2 ProcessingPipeline
- TGProcessingAgent

–°—Ä–∞–≤–Ω–∏—Ç—å:
- –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (topics, entities)
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ API –≤—ã–∑–æ–≤–æ–≤
- –°—Ç–æ–∏–º–æ—Å—Ç—å (tokens)

### 4. –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç—ã (30 –º–∏–Ω)

**–§–∞–π–ª**: `tests/test_agents.py`

```python
import pytest
from unittest.mock import patch, AsyncMock

class TestTGProcessingAgent:
    
    async def test_agent_creation(self):
        """Agent should be created with tools."""
        from tg_parser.agents import TGProcessingAgent
        agent = TGProcessingAgent()
        assert agent.agent.name == "TGProcessor"
        assert len(agent.agent.tools) >= 3
    
    async def test_process_message(self):
        """Agent should process message and return structured output."""
        # Mock the Runner to avoid actual API calls
        ...
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
tg_parser/
‚îú‚îÄ‚îÄ agents/                    # NEW
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ processing_agent.py   # TGProcessingAgent
‚îÇ   ‚îî‚îÄ‚îÄ tools/                # Agent tools
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ text_tools.py     # clean_text, normalize
‚îÇ       ‚îî‚îÄ‚îÄ extraction_tools.py  # entities, topics
‚îú‚îÄ‚îÄ api/                      # EXISTING (from 2A)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ processing/               # EXISTING (v1.2)
    ‚îî‚îÄ‚îÄ pipeline.py
```

---

## ‚úÖ Success Criteria

### Minimum (MVP)
- [ ] OpenAI Agents SDK —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- [ ] TGProcessingAgent —Å–æ–∑–¥–∞–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –£—Å–ø–µ—à–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ 5+ —Å–æ–æ–±—â–µ–Ω–∏–π
- [ ] –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã (mock)

### Stretch
- [ ] –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å v1.2
- [ ] Multi-agent prototype (Processing + Topicization)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å HTTP API endpoint `/api/v1/chat`

---

## üîß –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
source .venv/bin/activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Agents SDK
pip install openai-agents

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
pytest tests/test_agents.py -v

# –ó–∞–ø—É—Å–∫ API —Å–µ—Ä–≤–µ—Ä–∞
tg-parser api --port 8000

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
pytest tests/ -v --tb=short
```

---

## üìö –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

### –ë–∞–∑–æ–≤—ã–π –∞–≥–µ–Ω—Ç —Å tools:

```python
from agents import Agent, Runner, function_tool

@function_tool
def get_weather(city: str) -> str:
    """Get weather for a city."""
    return f"Sunny in {city}"

agent = Agent(
    name="Assistant",
    instructions="You help with weather queries.",
    tools=[get_weather],
    model="gpt-4o-mini",
)

result = await Runner.run(agent, "What's the weather in Moscow?")
print(result.final_output)
```

### Structured output —Å Pydantic:

```python
from pydantic import BaseModel
from agents import Agent

class ProcessingResult(BaseModel):
    text_clean: str
    topics: list[str]
    summary: str

agent = Agent(
    name="Processor",
    instructions="Process text and extract info",
    output_type=ProcessingResult,  # Structured output!
)
```

### Multi-agent —Å handoffs:

```python
from agents import Agent, handoff

processing_agent = Agent(
    name="Processing",
    handoff_description="Handles message processing",
)

topicization_agent = Agent(
    name="Topicization", 
    handoff_description="Groups messages by topic",
)

triage_agent = Agent(
    name="Triage",
    instructions="Route to appropriate agent",
    handoffs=[processing_agent, topicization_agent],
)
```

---

## üìù –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

1. –ö–∞–∫ Agents SDK –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ tools?
2. –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å batch processing —Å Agent?
3. –ö–∞–∫ –∏–∑–º–µ—Ä–∏—Ç—å token usage –¥–ª—è Agent vs direct API?
4. –ù—É–∂–µ–Ω –ª–∏ SQLiteSession –¥–ª—è –Ω–∞—à–µ–≥–æ use case?

---

**Version**: 1.0  
**Created**: 27 –¥–µ–∫–∞–±—Ä—è 2025  
**Status**: Ready for Phase 2B

